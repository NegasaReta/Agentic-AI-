{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90991bce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Tool-Using Agent. Type 'quit' to exit.\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 10.017019926s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 10\n}\n]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 143\u001b[39m\n\u001b[32m    140\u001b[39m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m143\u001b[39m     \u001b[43magent_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36magent_loop\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# Loop, handle tool-use chains until text response is given\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconversation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     tool_name, tool_args = get_function_call(response)\n\u001b[32m    121\u001b[39m     text = get_text(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/api_core/retry/retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:77\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 0, model: gemini-2.0-flash\nPlease retry in 10.017019926s. [links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_input_token_count\"\n  quota_id: \"GenerateContentInputTokensPerModelPerMinute-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\nviolations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n}\n, retry_delay {\n  seconds: 10\n}\n]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "\n",
    "GOOGLE_API_KEY = 'AIzaSyDnRy9o0i5WTjeqBWu9diVYR_xP-tiODvU'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "CITY_TZ = {\n",
    "    \"cape town\": 2,\n",
    "    \"london\": 0,\n",
    "    \"new york\": -5\n",
    "}\n",
    "def get_time(location: str):\n",
    "    loc = location.strip().lower()\n",
    "    if loc in CITY_TZ:\n",
    "        now = datetime.datetime.utcnow() + datetime.timedelta(hours=CITY_TZ[loc])\n",
    "        return f\"{now.strftime('%Y-%m-%d %H:%M')} (Local time in {location.title()})\"\n",
    "    return f\"Sorry, I don't know the time for '{location}'. Try Cape Town, London, or New York.\"\n",
    "\n",
    "def calc(expression: str):\n",
    "    try:\n",
    "        if not re.match(r\"^[0-9+\\-*/%. ()]+$\", expression):\n",
    "            raise ValueError(\"Expression contains invalid characters.\")\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: Invalid expression ({e})\"\n",
    "\n",
    "FAQ_KB = [\n",
    "    {\"q\": \"reset password\", \"answer\": \"Go to settings and click on 'Reset password'.\", \"source_title\": \"Account Help\"},\n",
    "    {\"q\": \"update email\", \"answer\": \"Go to profile > Edit to update your email.\", \"source_title\": \"Profile FAQ\"}\n",
    "]\n",
    "def lookup_faq(query: str):\n",
    "    q_lower = query.lower()\n",
    "    for entry in FAQ_KB:\n",
    "        if entry[\"q\"] in q_lower:\n",
    "            return f\"{entry['answer']} (Source: {entry['source_title']})\"\n",
    "    return \"Sorry, I have no answer for that. (Source: N/A)\"\n",
    "\n",
    "tool_map = {\n",
    "    \"get_time\": get_time,\n",
    "    \"calc\": calc,\n",
    "    \"lookup_faq\": lookup_faq\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"function_declarations\": [\n",
    "            {\n",
    "                \"name\": \"get_time\",\n",
    "                \"description\": \"Get local time for a known city.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\"type\": \"string\", \"description\": \"City name, e.g., Cape Town.\"}\n",
    "                    },\n",
    "                    \"required\": [\"location\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"calc\",\n",
    "                \"description\": \"Safely evaluate a numeric expression.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\"type\": \"string\", \"description\": \"Math expression, e.g. 5*6+1\"}\n",
    "                    },\n",
    "                    \"required\": [\"expression\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"lookup_faq\",\n",
    "                \"description\": \"Look up an FAQ answer by user query.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\"type\": \"string\", \"description\": \"Question or keywords.\"}\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash\",\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "def get_function_call(response):\n",
    "    for candidate in response.candidates:\n",
    "        for part in getattr(candidate.content, \"parts\", []):\n",
    "            if hasattr(part, \"function_call\"):\n",
    "                return part.function_call.name, part.function_call.args\n",
    "    return None, None\n",
    "\n",
    "def get_text(response):\n",
    "    # Returns string if a .text part exists, else None\n",
    "    for candidate in response.candidates:\n",
    "        for part in getattr(candidate.content, \"parts\", []):\n",
    "            if hasattr(part, \"text\"):\n",
    "                return part.text.strip()\n",
    "    return None\n",
    "\n",
    "def agent_loop():\n",
    "    print(\"Gemini Tool-Using Agent. Type 'quit' to exit.\")\n",
    "    conversation = []\n",
    "    while True:\n",
    "        user = input(\"User: \")\n",
    "        if user.strip().lower() in (\"quit\", \"exit\"):\n",
    "            break\n",
    "\n",
    "        conversation.append({\"role\": \"user\", \"parts\": [user]})\n",
    "\n",
    "        # Loop, handle tool-use chains until text response is given\n",
    "        while True:\n",
    "            response = model.generate_content(conversation)\n",
    "            tool_name, tool_args = get_function_call(response)\n",
    "            text = get_text(response)\n",
    "\n",
    "            if tool_name and tool_name in tool_map:\n",
    "                # Tool call needed\n",
    "                tool_func = tool_map[tool_name]\n",
    "                try:\n",
    "                    result = tool_func(**tool_args)\n",
    "                except Exception as e:\n",
    "                    result = f\"Tool error: {e}\"\n",
    "                conversation.append({\n",
    "                    \"role\": \"model\",\n",
    "                    \"parts\": [str(result)]\n",
    "                })\n",
    "                continue  # ask Gemini again with updated context\n",
    "            elif text:\n",
    "                print(\"Agent:\", text)\n",
    "                break  # done, got a natural language answer\n",
    "            else:\n",
    "                print(\"Agent: [No text answer and no function call in model response!]\")\n",
    "                break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce17dfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Tool-Using Agent. Type 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Hello! How can I help you today?\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not convert `part.function_call` to text.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 131\u001b[39m\n\u001b[32m    128\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAgent:\u001b[39m\u001b[33m\"\u001b[39m, response.text.strip())\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     \u001b[43magent_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 128\u001b[39m, in \u001b[36magent_loop\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    126\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAgent:\u001b[39m\u001b[33m\"\u001b[39m, response.text.strip())\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAgent:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m.strip())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/types/generation_types.py:536\u001b[39m, in \u001b[36mBaseGenerateContentResponse.text\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    533\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    535\u001b[39m     part_type = protos.Part.pb(part).WhichOneof(\u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCould not convert `part.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpart_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` to text.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(texts)\n",
      "\u001b[31mValueError\u001b[39m: Could not convert `part.function_call` to text."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Use your provided API key.\n",
    "GOOGLE_API_KEY = 'AIzaSyDnRy9o0i5WTjeqBWu9diVYR_xP-tiODvU'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# -- Tool Logic ---\n",
    "CITY_TZ = {\n",
    "    \"cape town\": 2,\n",
    "    \"london\": 0,\n",
    "    \"new york\": -5\n",
    "}\n",
    "def get_time(location: str):\n",
    "    loc = location.strip().lower()\n",
    "    if loc in CITY_TZ:\n",
    "        now = datetime.datetime.utcnow() + datetime.timedelta(hours=CITY_TZ[loc])\n",
    "        return f\"{now.strftime('%Y-%m-%d %H:%M')} (Local time in {location.title()})\"\n",
    "    return f\"Sorry, I don't know the time for '{location}'. Try Cape Town, London, or New York.\"\n",
    "\n",
    "def calc(expression: str):\n",
    "    try:\n",
    "        if not re.match(r\"^[0-9+\\-*/%. ()]+$\", expression):\n",
    "            raise ValueError(\"Expression contains invalid characters.\")\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: Invalid expression ({e})\"\n",
    "\n",
    "FAQ_KB = [\n",
    "    {\"q\": \"reset password\", \"answer\": \"Go to settings and click on 'Reset password'.\", \"source_title\": \"Account Help\"},\n",
    "    {\"q\": \"update email\",   \"answer\": \"Go to profile > Edit to update your email.\", \"source_title\": \"Profile FAQ\"}\n",
    "]\n",
    "def lookup_faq(query: str):\n",
    "    q_lower = query.lower()\n",
    "    for entry in FAQ_KB:\n",
    "        if entry[\"q\"] in q_lower:\n",
    "            return f\"{entry['answer']} (Source: {entry['source_title']})\"\n",
    "    return \"Sorry, I have no answer for that. (Source: N/A)\"\n",
    "\n",
    "tool_map = {\n",
    "    \"get_time\": get_time,\n",
    "    \"calc\": calc,\n",
    "    \"lookup_faq\": lookup_faq\n",
    "}\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"function_declarations\": [\n",
    "            {\n",
    "                \"name\": \"get_time\",\n",
    "                \"description\": \"Get local time for a known city.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"location\": {\"type\": \"string\", \"description\": \"City name, e.g., Cape Town.\"}\n",
    "                    },\n",
    "                    \"required\": [\"location\"]\n",
    "                },\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"calc\",\n",
    "                \"description\": \"Safely evaluate a numeric expression.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"expression\": {\"type\": \"string\", \"description\": \"Math expression, e.g. 5*6+1\"}\n",
    "                    },\n",
    "                    \"required\": [\"expression\"]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"lookup_faq\",\n",
    "                \"description\": \"Look up an FAQ answer by user query.\",\n",
    "                \"parameters\": {\n",
    "                    \"type\": \"object\",\n",
    "                    \"properties\": {\n",
    "                        \"query\": {\"type\": \"string\", \"description\": \"Question or keywords.\"}\n",
    "                    },\n",
    "                    \"required\": [\"query\"]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\",  # also works with 'gemini-pro'\n",
    "    tools=tools\n",
    ")\n",
    "\n",
    "def extract_function_call(response):\n",
    "    for candidate in response.candidates:\n",
    "        for part in getattr(candidate.content, \"parts\", []):\n",
    "            if hasattr(part, \"function_call\"):\n",
    "                name = part.function_call.name\n",
    "                args = part.function_call.args\n",
    "                return name, args\n",
    "    return None, None\n",
    "\n",
    "def agent_loop():\n",
    "    print(\"Gemini Tool-Using Agent. Type 'quit' to exit.\")\n",
    "    conversation = []\n",
    "    while True:\n",
    "        user = input(\"User: \")\n",
    "        if user.strip().lower() in (\"quit\", \"exit\"):\n",
    "            break\n",
    "\n",
    "        conversation.append({\"role\": \"user\", \"parts\": [user]})\n",
    "        response = model.generate_content(conversation)\n",
    "\n",
    "        tool_name, tool_args = extract_function_call(response)\n",
    "        if tool_name and tool_name in tool_map:\n",
    "            tool_func = tool_map[tool_name]\n",
    "            try:\n",
    "                result = tool_func(**tool_args)\n",
    "            except Exception as e:\n",
    "                result = f\"Tool error: {e}\"\n",
    "            conversation.append({\n",
    "                \"role\": \"function\",\n",
    "                \"parts\": [str(result)]\n",
    "            })\n",
    "            response = model.generate_content(conversation)\n",
    "            print(\"Agent:\", response.text.strip())\n",
    "        else:\n",
    "            print(\"Agent:\", response.text.strip())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8027ebb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "GenerativeModel.__init__() got an unexpected keyword argument 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     46\u001b[39m functions = [\n\u001b[32m     47\u001b[39m     {\n\u001b[32m     48\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mname\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mget_time\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     82\u001b[39m     },\n\u001b[32m     83\u001b[39m ]\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Register functions in the model:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m model = \u001b[43mgenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGenerativeModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34magent_loop\u001b[39m():\n\u001b[32m     89\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mGemini Tool-Using Agent (function calling). \u001b[39m\u001b[33m'\u001b[39m\u001b[33mquit\u001b[39m\u001b[33m'\u001b[39m\u001b[33m to exit.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: GenerativeModel.__init__() got an unexpected keyword argument 'functions'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import datetime\n",
    "import re\n",
    "import google.generativeai as genai\n",
    "\n",
    "GOOGLE_API_KEY = os.environ.get(\"GOOGLE_API_KEY\") or 'AIzaSyDnRy9o0i5WTjeqBWu9diVYR_xP-tiODvU'\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# --- TOOL LOGIC ---\n",
    "\n",
    "CITY_TZ = {\n",
    "    \"cape town\": 2,\n",
    "    \"london\": 0,\n",
    "    \"new york\": -5\n",
    "}\n",
    "def get_time(location: str) -> str:\n",
    "    loc = location.strip().lower()\n",
    "    if loc in CITY_TZ:\n",
    "        now = datetime.datetime.utcnow() + datetime.timedelta(hours=CITY_TZ[loc])\n",
    "        return f\"{now.strftime('%Y-%m-%d %H:%M')} (Local time in {location.title()})\"\n",
    "    return f\"Sorry, I don't know the time for '{location}'. Try: Cape Town, London, New York.\"\n",
    "\n",
    "def calc(expression: str) -> str:\n",
    "    try:\n",
    "        if not re.match(r\"^[0-9+\\-*/%. ()]+$\", expression):\n",
    "            raise ValueError(\"Expression contains invalid characters.\")\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return str(result)\n",
    "    except Exception as e:\n",
    "        return f\"Error: Invalid expression ({e})\"\n",
    "\n",
    "FAQ_KB = [\n",
    "    {\"q\": \"reset password\", \"answer\": \"Go to settings and click on 'Reset password'.\", \"source_title\": \"Account Help\"},\n",
    "    {\"q\": \"update email\",   \"answer\": \"Go to profile > Edit to update your email.\", \"source_title\": \"Profile FAQ\"}\n",
    "]\n",
    "def lookup_faq(query: str) -> str:\n",
    "    q_lower = query.lower()\n",
    "    for entry in FAQ_KB:\n",
    "        if entry[\"q\"] in q_lower:\n",
    "            return f\"{entry['answer']} (Source: {entry['source_title']})\"\n",
    "    return \"Sorry, I have no answer for that. (Source: N/A)\"\n",
    "\n",
    "# --- WRAP FOR GEMINI SDK FUNCTION CALLING ---\n",
    "\n",
    "# This new syntax is needed for Gemini function calling! (SDK v0.6+)\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_time\",\n",
    "        \"description\": \"Get local time for a known city.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"location\": {\"type\": \"string\", \"description\": \"City name, e.g., Cape Town.\"}\n",
    "            },\n",
    "            \"required\": [\"location\"]\n",
    "        },\n",
    "        \"function\": get_time,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"calc\",\n",
    "        \"description\": \"Safely evaluate a numeric expression.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"expression\": {\"type\": \"string\", \"description\": \"Math expression, e.g. 5*6+1\"}\n",
    "            },\n",
    "            \"required\": [\"expression\"]\n",
    "        },\n",
    "        \"function\": calc,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"lookup_faq\",\n",
    "        \"description\": \"Look up an FAQ answer by user query.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\"type\": \"string\", \"description\": \"Question or keywords.\"}\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        },\n",
    "        \"function\": lookup_faq,\n",
    "    },\n",
    "]\n",
    "\n",
    "# Register functions in the model:\n",
    "model = genai.GenerativeModel(model_name=\"gemini-2.5-flash\", functions=functions)\n",
    "\n",
    "def agent_loop():\n",
    "    print(\"Gemini Tool-Using Agent (function calling). 'quit' to exit.\")\n",
    "    chat = model.start_chat()\n",
    "    while True:\n",
    "        user = input(\"User: \")\n",
    "        if user.strip().lower() in (\"quit\", \"exit\"):\n",
    "            break\n",
    "        response = chat.send_message(user, stream=False)\n",
    "        print(\"Agent:\", response.text.strip())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    agent_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280c19a9",
   "metadata": {},
   "source": [
    "##Session 2 Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f2c09e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "import json\n",
    "os.environ[\"GOOGLE_API_KEY\"] ='AIzaSyDnRy9o0i5WTjeqBWu9diVYR_xP-tiODvU'\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2133b59",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown field for FunctionDeclaration: type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mgenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGenerativeModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m chat = model.start_chat(history=[\n\u001b[32m      6\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      7\u001b[39m      \u001b[33m\"\u001b[39m\u001b[33mparts\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mYou are a helpful AI agent that can use tools to assist users with their requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m      }\n\u001b[32m      9\u001b[39m ])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/generative_models.py:87\u001b[39m, in \u001b[36mGenerativeModel.__init__\u001b[39m\u001b[34m(self, model_name, safety_settings, generation_config, tools, tool_config, system_instruction)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m._safety_settings = safety_types.to_easy_safety_dict(safety_settings)\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m._generation_config = generation_types.to_generation_config_dict(generation_config)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28mself\u001b[39m._tools = \u001b[43mcontent_types\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_function_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tool_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mself\u001b[39m._tool_config = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/types/content_types.py:917\u001b[39m, in \u001b[36mto_function_library\u001b[39m\u001b[34m(lib)\u001b[39m\n\u001b[32m    915\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFunctionLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/types/content_types.py:855\u001b[39m, in \u001b[36mFunctionLibrary.__init__\u001b[39m\u001b[34m(self, tools)\u001b[39m\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tools: Iterable[ToolType]):\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m     tools = \u001b[43m_make_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m     \u001b[38;5;28mself\u001b[39m._tools = \u001b[38;5;28mlist\u001b[39m(tools)\n\u001b[32m    857\u001b[39m     \u001b[38;5;28mself\u001b[39m._index = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/types/content_types.py:898\u001b[39m, in \u001b[36m_make_tools\u001b[39m\u001b[34m(tools)\u001b[39m\n\u001b[32m    896\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe only string that can be passed as a tool is \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcode_execution\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tools, Iterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tools, Mapping):\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m     tools = [\u001b[43m_make_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools]\n\u001b[32m    899\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tools) > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(t.function_declarations) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools):\n\u001b[32m    900\u001b[39m         \u001b[38;5;66;03m# flatten into a single tool.\u001b[39;00m\n\u001b[32m    901\u001b[39m         tools = [_make_tool([t.function_declarations[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools])]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/types/content_types.py:823\u001b[39m, in \u001b[36m_make_tool\u001b[39m\u001b[34m(tool)\u001b[39m\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    822\u001b[39m         fd = tool\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Tool(function_declarations=[\u001b[43mprotos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFunctionDeclaration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    825\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tool.lower() == \u001b[33m\"\u001b[39m\u001b[33mcode_execution\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/proto/message.py:724\u001b[39m, in \u001b[36mMessage.__init__\u001b[39m\u001b[34m(self, mapping, ignore_unknown_fields, **kwargs)\u001b[39m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ignore_unknown_fields:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    725\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnknown field for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, key)\n\u001b[32m    726\u001b[39m     )\n\u001b[32m    728\u001b[39m pb_value = marshal.to_proto(pb_type, value)\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pb_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Unknown field for FunctionDeclaration: type"
     ]
    }
   ],
   "source": [
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.5-flash\",\n",
    "    tools=tools\n",
    ")\n",
    "chat = model.start_chat(history=[\n",
    "    {\"role\": \"user\", \n",
    "     \"parts\": \"You are a helpful AI agent that can use tools to assist users with their requests.\"\n",
    "     }\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c269223d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_time\",\n",
    "            \"description\": \"Get the current time for a given location\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City name\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"calc\",\n",
    "            \"description\": \"Evaluate a mathematical expression\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Math expression like 0.18 * 24500\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"lookup_faq\",\n",
    "            \"description\": \"Search FAQ knowledge base\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34787196",
   "metadata": {},
   "source": [
    "Tool Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f189d6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time (location: str) -> str:\n",
    "    times = {\n",
    "        \"New York\": \"14:30 SAST\",\n",
    "        \"Addis Ababa\": \"15:30 EAT\",\n",
    "        \"UTC\": \"12:30 UTC\"\n",
    "    }\n",
    "    return times.get(location, \"Location not found.\")\n",
    "\n",
    "def calc (expression: str) -> str:\n",
    "    try:\n",
    "        return str(eval(expression))\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "    \n",
    "def lookup_faq (query: str) -> str:\n",
    "    faqs = {\n",
    "         \"agentic ai\": (\n",
    "        \"Agentic AI refers to artificial intelligence systems that can act autonomously to achieve specific goals.\",\n",
    "        \"AI Basics\"\n",
    "    ),\n",
    "         \"calculator\":(\"The calc function evaluates mathematical expressions provided as strings and returns the result.\",\"Calculator Tool\")\n",
    "    }\n",
    "    return faqs.get(query.lower(), \"FAQ not found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0d02a8",
   "metadata": {},
   "source": [
    "Agent State Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d942c6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"last_goals\": [],\n",
    "    \"last_tool_result\": None,\n",
    "    \"last_location\": None\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746fa3f6",
   "metadata": {},
   "source": [
    "Gemini-Tool Calling Agent Loop (CORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a7f0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown field for FunctionDeclaration: type",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model = \u001b[43mgenai\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGenerativeModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m chat = model.start_chat(history=[\n\u001b[32m      6\u001b[39m     {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m      7\u001b[39m      \u001b[33m\"\u001b[39m\u001b[33mparts\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mYou are a helpful AI agent that can use tools to assist users with their requests.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m      }\n\u001b[32m      9\u001b[39m ])\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/generative_models.py:87\u001b[39m, in \u001b[36mGenerativeModel.__init__\u001b[39m\u001b[34m(self, model_name, safety_settings, generation_config, tools, tool_config, system_instruction)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28mself\u001b[39m._safety_settings = safety_types.to_easy_safety_dict(safety_settings)\n\u001b[32m     86\u001b[39m \u001b[38;5;28mself\u001b[39m._generation_config = generation_types.to_generation_config_dict(generation_config)\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m \u001b[38;5;28mself\u001b[39m._tools = \u001b[43mcontent_types\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_function_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tool_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     90\u001b[39m     \u001b[38;5;28mself\u001b[39m._tool_config = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/types/content_types.py:917\u001b[39m, in \u001b[36mto_function_library\u001b[39m\u001b[34m(lib)\u001b[39m\n\u001b[32m    915\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFunctionLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlib\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/types/content_types.py:855\u001b[39m, in \u001b[36mFunctionLibrary.__init__\u001b[39m\u001b[34m(self, tools)\u001b[39m\n\u001b[32m    854\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tools: Iterable[ToolType]):\n\u001b[32m--> \u001b[39m\u001b[32m855\u001b[39m     tools = \u001b[43m_make_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    856\u001b[39m     \u001b[38;5;28mself\u001b[39m._tools = \u001b[38;5;28mlist\u001b[39m(tools)\n\u001b[32m    857\u001b[39m     \u001b[38;5;28mself\u001b[39m._index = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/types/content_types.py:898\u001b[39m, in \u001b[36m_make_tools\u001b[39m\u001b[34m(tools)\u001b[39m\n\u001b[32m    896\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mThe only string that can be passed as a tool is \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcode_execution\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    897\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tools, Iterable) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tools, Mapping):\n\u001b[32m--> \u001b[39m\u001b[32m898\u001b[39m     tools = [\u001b[43m_make_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools]\n\u001b[32m    899\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tools) > \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28mlen\u001b[39m(t.function_declarations) == \u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools):\n\u001b[32m    900\u001b[39m         \u001b[38;5;66;03m# flatten into a single tool.\u001b[39;00m\n\u001b[32m    901\u001b[39m         tools = [_make_tool([t.function_declarations[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m tools])]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/google/generativeai/types/content_types.py:823\u001b[39m, in \u001b[36m_make_tool\u001b[39m\u001b[34m(tool)\u001b[39m\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    822\u001b[39m         fd = tool\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Tool(function_declarations=[\u001b[43mprotos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mFunctionDeclaration\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfd\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    825\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tool.lower() == \u001b[33m\"\u001b[39m\u001b[33mcode_execution\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Development/ml-env/lib/python3.12/site-packages/proto/message.py:724\u001b[39m, in \u001b[36mMessage.__init__\u001b[39m\u001b[34m(self, mapping, ignore_unknown_fields, **kwargs)\u001b[39m\n\u001b[32m    721\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ignore_unknown_fields:\n\u001b[32m    722\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m724\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    725\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mUnknown field for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m, key)\n\u001b[32m    726\u001b[39m     )\n\u001b[32m    728\u001b[39m pb_value = marshal.to_proto(pb_type, value)\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pb_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Unknown field for FunctionDeclaration: type"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"User: \")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        break\n",
    "    response = chat.send_message(user_input)\n",
    "    #check for tool calls\n",
    "    if response.candidates[0].content.parts[0].function_call:\n",
    "        fc =  response.candidates[0].content.parts[0].function_call  \n",
    "        tool_name = fc.name\n",
    "        args = dict(fc.args)\n",
    "        \n",
    "        if tool_name == \"get_time\":\n",
    "            result = get_time(args[\"location\"])\n",
    "            state[\"last_location\"] = args[\"location\"]\n",
    "        elif tool_name == \"calc\":\n",
    "            result = calc(args[\"expression\"])\n",
    "        elif tool_name == \"lookup_faq\":\n",
    "            result = lookup_faq(args[\"query\"])\n",
    "            \n",
    "        state[\"last_tool_result\"] = result\n",
    "        \n",
    "        #send tool result back to Gemini\n",
    "        follow_up = chat.send_message(\n",
    "            genai.protos.Content(\n",
    "                parts=[\n",
    "                    genai.protos.Content.Part(\n",
    "                        function_response=genai.protos.FunctionResponse(\n",
    "                            name = tool_name,\n",
    "                            response = {\"result\": result})\n",
    "                    )]\n",
    "            )\n",
    "            \n",
    "        )\n",
    "        print(\"\\nAI Agent:\", follow_up.text)\n",
    "    else:\n",
    "        print(\"\\nAI Agent:\", response.text)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4336c0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
